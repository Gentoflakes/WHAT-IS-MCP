How are reponses actually generated from server? 

1. TOOLS -> actual implementators

Tools are schema-defined interfaces that LLMs can invoke. MCP uses JSON Schema for validation. Each tool performs a single operation with clearly defined inputs and outputs. 

***Most importantly, tool execution requires explicit user approval, ensuring users maintain control over actions taken by a model -> The feared AGI checkpoint. 

- Protocol operations:
Method	    Purpose	                    Returns
tools/list	Discover available tools	Array of tool definitions with schemas
tools/call	Execute a specific tool	    Tool execution result

- Sample tool defination : 

{
  name: "searchFlights",
  description: "Search for available flights",
  inputSchema: {
    type: "object",
    properties: {
      origin: { type: "string", description: "Departure city" },
      destination: { type: "string", description: "Arrival city" },
      date: { type: "string", format: "date", description: "Travel date" }
    },
    required: ["origin", "destination", "date"]
  }
}


- User-Model interaction : For trust and safety, applications MUST enforce manual approval to give humans the ability to deny tool invocations. Applications typically implement this through approval dialogs, permission settings for pre-approving certain safe operations, and activity logs that show all tool executions with their results.


2. Resources : The actual context

- Resources expose data from files, APIs, databases, or any other source that an AI needs to understand context. Applications can access this information directly and decide how to use it.

- resource identification : Resources use URI-based identification, with each resource having a unique URI such as file:///path/to/document.md

- Resource Templates : enable dynamic resource access through URI templates. A template like travel://activities/{city}/{category} would access filtered activity data by substituting both {city} and {category} parameters.


-  This way resources provide the AI application with access to relevant information.

- Instead of manually copying this information, resources provide raw information to AI applications. The application can choose how to best handle the data. Applications might choose to select a subset of data, using embeddings or keyword search, or pass the raw data from a resource directly to a model

- This information is first fetched on the client side and processed locally only then sent to the model.

3. Parameter Completion -> advance feature to give better user interaction by autocompletion -> can cause long overhead to servers so caution!


4. Prompts - Interaction Templates -> best way to communicate

Prompts are structured templates that define expected inputs and interaction patterns. They are user-controlled, requiring explicit invocation rather than automatic triggering. Prompts can be context-aware, referencing available resources and tools to create comprehensive workflows. Like resources, prompts support parameter completion to help users discover valid argument values.


- Protocol operations:
Method	        Purpose	                            Returns
prompts/list	Discover available prompts	        Array of prompt descriptors
prompts/get	    Retrieve prompt details	            Full prompt definition with arguments


- example vacation planner template : 
{
  "name": "plan-vacation",
  "title": "Plan a vacation",
  "description": "Guide through vacation planning process",
  "arguments": [
    { "name": "destination", "type": "string", "required": true },
    { "name": "duration", "type": "number", "description": "days" },
    { "name": "budget", "type": "number", "required": false },
    { "name": "interests", "type": "array", "items": { "type": "string" } }
  ]
}

Rather than unstructured natural language input, the prompt system enables:

1. Selection of the “Plan a vacation” template
2. Structured input: Barcelona, 7 days, $3000, [“beaches”, “architecture”, “food”]
3. Consistent workflow execution based on the template



--------------------------------------------------
COMPLETE WORKFLOW : 

The real power of MCP emerges when multiple servers work together, combining their specialized capabilities through a unified interface.
​
Example: Multi-Server Travel Planning
Consider an AI application with three connected servers:
Travel Server - Handles flights, hotels, and itineraries
Weather Server - Provides climate data and forecasts
Calendar/Email Server - Manages schedules and communications


User invokes a prompt with parameters:

Copy
{
  "prompt": "plan-vacation",
  "arguments": {
    "destination": "Barcelona",
    "departure_date": "2024-06-15",
    "return_date": "2024-06-22",
    "budget": 3000,
    "travelers": 2
  }
}

User selects resources to include:
calendar://my-calendar/June-2024 (from Calendar Server)
travel://preferences/europe (from Travel Server)
travel://past-trips/Spain-2023 (from Travel Server)


Final step : 
AI processes the request: The AI first reads all selected resources to gather context. From the calendar, it identifies available dates. From travel preferences, it learns preferred airlines and hotel types. From past trips, it discovers previously enjoyed locations. From weather data, it checks climate conditions for the travel period. Using this context, the AI then requests user approval to execute a series of coordinated actions: searching for flights from NYC to Barcelona, finding hotels within the specified budget, creating a calendar event for the trip duration, and sending confirmation emails with the trip details.